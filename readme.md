# Market Data Microservice

A real-time market data microservice designed with FastAPI, Kafka, PostgreSQL, Redis, and Docker. This system allows polling of stock prices from providers like YFinance, stores raw and processed data, and serves the latest price efficiently using Redis caching.

---

## Features

* **FastAPI REST Interface** for polling and fetching stock prices
* **YFinance Provider Integration** to fetch real-time prices
* **Polling Job System** to schedule repeated data pulls
* **Kafka Message Queue** for decoupling data fetch and processing
* **PostgreSQL Database** for storing raw and computed data
* **Redis Cache** to serve latest prices quickly
* **Dockerized Setup** with multi-container orchestration
* **Swagger UI** for testing the API

---

## Architecture Overview

```
Client â”€â”€> FastAPI â”€â”€â”¬â”€â”€â”€â”€> PostgreSQL (Raw Prices + Moving Averages)
                    â”‚
                    â”œâ”€â”€â”€â”€> Kafka Producer â”€â”€> Kafka â”€â”€> Consumer â”€â”€> DB + Redis
                    â”‚
                    â””â”€â”€â”€â”€> YFinance API (price polling)
```

---

## Technologies Used

* **FastAPI** â€” Lightweight modern Python web framework
* **YFinance** â€” Market data provider
* **PostgreSQL** â€” Persistent storage for raw and processed prices
* **Kafka + Zookeeper** â€” Message brokering between polling and consumer logic
* **Redis** â€” In-memory cache to serve latest prices quickly
* **Docker** â€” Containerization of all services
* **Uvicorn** â€” ASGI server to run FastAPI

---

## Folder Structure

```
market-data-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/          # FastAPI routes
â”‚   â”œâ”€â”€ core/         # DB & Redis connections
â”‚   â”œâ”€â”€ models/       # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas/      # Pydantic request/response schemas
â”‚   â””â”€â”€ services/     # Kafka, polling, providers
â”œâ”€â”€ scripts/          # Polling runner & consumer
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env              # Environment variables
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/dhruvish20/market-data-service.git
cd market-data-service
```

### 2. Configure Environment Variables

Create a `.env` file with:

```ini
DB_HOST=db
DB_PORT=5432
DB_NAME=marketdata
DB_USER=postgres
DB_PASSWORD=postgres
REDIS_HOST=redis
REDIS_PORT=6379
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
```

### 3. Launch Services

```bash
docker-compose up --build -d
```

### 4. Initialize the Database

```bash
docker-compose exec app bash -c "PYTHONPATH=/app python scripts/init_db.py"
```

---

## ğŸ§ª API Usage

Visit Swagger UI:

```
http://localhost:8000/docs
```

### POST `/prices/poll`

Schedule a polling job:

```json
{
  "symbols": ["AAPL"],
  "interval": 60,
  "provider": "yfinance"
}
```

### GET `/prices/latest`

Query latest price (uses Redis cache if available):

```http
/prices/latest?symbol=AAPL&provider=yfinance
```

### GET `/test-db`

Health check for DB connection.

---

## Running Background Services

### Run Polling Job Runner

```bash
docker-compose exec app bash -c "PYTHONPATH=/app python scripts/run_polling_jobs.py"
```

### Run Kafka Consumer

```bash
docker-compose exec app bash -c "PYTHONPATH=/app python scripts/consumer.py"
```

---

## Key Concepts Explained

### Polling Jobs

Defined via POST `/prices/poll`, they store symbol, provider, and interval in DB. A background runner checks every second for due jobs and fetches fresh prices.

### Kafka Event Pipeline

When a new price is fetched:

1. It is stored in `raw_market_data`
2. A Kafka message is published
3. Kafka consumer computes the moving average of latest 5 prices
4. The result is saved to `symbol_averages` and cached in Redis

### Redis Caching

When the client calls `/prices/latest`, the system:

* First checks Redis (`latest_price_{symbol}_{provider}`)
* If not found, fetches from DB and sets cache with TTL (e.g., 5 mins)

---

##  Deployment (AWS EC2)

### EC2 Setup

* Ubuntu 22.04 t2.micro
* Open ports: 22 (SSH), 8000 (FastAPI), 9092 (Kafka)

### Clone, Setup & Run

```bash
ssh -i ~/.ssh/your-key.pem ubuntu@<EC2-PUBLIC-IP>
git clone <your-repo>
cd market-data-service
nano .env
sudo docker-compose up -d --build
```

### Start Scripts

```bash
sudo docker-compose exec app bash -c "PYTHONPATH=/app python scripts/init_db.py"
sudo docker-compose exec app bash -c "PYTHONPATH=/app python scripts/run_polling_jobs.py"
sudo docker-compose exec app bash -c "PYTHONPATH=/app python scripts/consumer.py"
```

---

## What's Working

* âœ… End-to-end polling of stock prices via YFinance
* âœ… Kafka message queue and consumer logic
* âœ… Moving average computation
* âœ… Redis caching and TTL logic
* âœ… Dockerized deployment
* âœ… Hosted Swagger UI

---

## Future Improvements

* Add `/prices/average` endpoint to expose moving averages
* Add test suite using Pytest
* Auto-scale consumer and polling runners
* Grafana dashboard integration

---

## Contact

Built by Dhruvish Parekh â€” Open to feedback and collaboration!
